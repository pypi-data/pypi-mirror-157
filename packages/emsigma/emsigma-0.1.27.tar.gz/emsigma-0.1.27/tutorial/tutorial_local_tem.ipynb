{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTooJbLTkDWl"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "4362PEEZfpQB",
    "outputId": "3225a4d8-7859-46d9-e634-2d86d52c23e0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sigma\n",
    "from sigma.utils import normalisation as norm \n",
    "from sigma.utils import visualisation as visual\n",
    "from sigma.utils.load import SEMDataset\n",
    "from sigma.utils.loadtem import TEMDataset\n",
    "from sigma.src.utils import same_seeds\n",
    "from sigma.src.dim_reduction import Experiment\n",
    "from sigma.models.autoencoder import AutoEncoder\n",
    "from sigma.src.segmentation import PixelSegmenter\n",
    "from sigma.gui import gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olPzlO4gsAuG"
   },
   "source": [
    "# Load emi/ser files\n",
    "Note that the `.emi` and the corresponding `.ser` files should be place in the same folder, e.g., `test.emi` and `test.ser` should be in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wd0omy47rJb"
   },
   "outputs": [],
   "source": [
    "file_path = '.' # file path \n",
    "tem = TEMDataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpqYK5B6m-3k"
   },
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the dataset\n",
    "\n",
    "Use `gui.view_emi_dataset(tem)` to check the BSE image, the sum spectrum, and the elemental maps. Here we can use the small widgets to search the energy peaks and determine the elements for further amalyses. \n",
    "\n",
    "After setting the `Feature list`, we obtain the elemental maps hyperspectral imaging dataset (HSI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.set_xray_lines(['C_Ka', 'O_Ka', 'Fe_La','Mg_Ka', 'Al_Ka', 'Si_Ka', \n",
    "                    'S_Ka', 'Ca_Ka', 'Ca_Kb', 'Fe_Ka', 'Fe_Kb', 'Co_Ka', \n",
    "                    'Ni_Ka','Cu_Ka', 'Cu_Kb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRccG0O2plY_"
   },
   "outputs": [],
   "source": [
    "gui.view_emi_dataset(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjNVT8T9ttZx"
   },
   "source": [
    "## Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kwTAEa5rz7r"
   },
   "outputs": [],
   "source": [
    "# Rebin both edx and bse dataset\n",
    "tem.rebin_signal(size=(2,2))\n",
    "\n",
    "# normalisation to make the spectrum of each pixel summing to 1.\n",
    "tem.peak_intensity_normalisation()\n",
    "\n",
    "# Remove the first peak until the energy of 0.1 keV\n",
    "tem.remove_fist_peak(end=0.1) \n",
    "\n",
    "# Denoise the X-ray profile using PCA.\n",
    "tem.peak_denoising_PCA(n_components_to_reconstruct=10, plot_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NARhLv5ASNry"
   },
   "outputs": [],
   "source": [
    "# View the dataset (bse, edx etc.) again to check differences.\n",
    "gui.view_emi_dataset(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing steps yield a HSI datacube with the dimension of 139 x 257 x 9 (due to the 2x2 binning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59GFs_0SBSkW"
   },
   "source": [
    "## Normalisation\n",
    "\n",
    "Before dimensionality reduction, we normalise the elemental maps use `tem.normalisation()`, where we can pass a list containing (optional) sequential normalisation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgCJ-sfVsNbb"
   },
   "outputs": [],
   "source": [
    "# Normalise the dataset using the (optional) sequential three methods.\n",
    "tem.normalisation([norm.neighbour_averaging, \n",
    "                   norm.zscore, \n",
    "                   norm.softmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `gui.view_pixel_distributions` to view the intensity distributions after each sequential normalisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXRo2LvTqxbK"
   },
   "outputs": [],
   "source": [
    "gui.view_pixel_distributions(tem, \n",
    "                             norm_list=[norm.neighbour_averaging,\n",
    "                                        norm.zscore,\n",
    "                                        norm.softmax], \n",
    "                             peak='Fe_Ka', \n",
    "                             cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PaFMEOprt3B"
   },
   "source": [
    "## (Optional) Assign RGB to elemental peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZSQgdJsZTgV"
   },
   "outputs": [],
   "source": [
    "gui.view_rgb(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check elemental distribution after normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uns525mlsjfm"
   },
   "outputs": [],
   "source": [
    "print('After normalisation:')\n",
    "gui.view_intensity_maps(edx=tem.normalised_elemental_data, element_list=tem.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2GcAoSlnGuN"
   },
   "source": [
    "# Dimensionality reduction: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_7bn6yJBjNo"
   },
   "source": [
    "## Initialise experiment / model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUcL2sddrLHC",
    "outputId": "2bc7fd73-d250-40f8-c5b1-755e13058bcb"
   },
   "outputs": [],
   "source": [
    "# The integer in this function can determine different initialised parameters of model (tuning sudo randomness)\n",
    "# This can influence the result of dimensionality reduction and change the latent space.\n",
    "same_seeds(1)\n",
    "\n",
    "# Set up the experiment, e.g. determining the model structure, dataset for training etc.\n",
    "general_results_dir='./' \n",
    "ex = Experiment(descriptor='softmax',\n",
    "                general_results_dir=general_results_dir,\n",
    "                model=AutoEncoder,\n",
    "                model_args={'hidden_layer_sizes':(512,256,128)}, # number of hidden layers and corresponding neurons\n",
    "                chosen_dataset=tem.normalised_elemental_data,\n",
    "                save_model_every_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEgWJf45Bp4F"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgajwhO3rNv1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ex.run_model(num_epochs=100,\n",
    "             patience=50, \n",
    "             batch_size=64,\n",
    "             learning_rate=1e-4, \n",
    "             weight_decay=0.0, \n",
    "             task='train_all', # Change to 'train_eval' to train on the training set (85% dataset) and test on a testing set (15%) for evaluation\n",
    "             noise_added=0.0,\n",
    "             KLD_lambda=0.0,\n",
    "             criterion='MSE',\n",
    "             lr_scheduler_args={'factor':0.5,\n",
    "                                'patience':5, \n",
    "                                'threshold':1e-2, \n",
    "                                'min_lr':1e-6,\n",
    "                                'verbose':True}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd5l795DnL8r"
   },
   "source": [
    "# Pixel segmentation: Gaussian mixture modelling (GMM) clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXi8fj7mBsxt"
   },
   "source": [
    "## (Optional) Load pre-trained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l8O-UwrjcxP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = './' # model path\n",
    "ex.load_trained_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_qEVkRAV7BL"
   },
   "source": [
    "## Measure Baysian information criterion (BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gui.view_bic` iteratively calculates the BIC for Gaussian mixture models using the number of Gaussian components `n_components`, e.g. if `n_components=20`, it shows the BIC values for GMM using n_components from 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FP2TyaUrL-D0"
   },
   "outputs": [],
   "source": [
    "latent = ex.get_latent()\n",
    "gui.view_bic(latent,\n",
    "             n_components=20,\n",
    "             model_args={'random_state':6, 'init_params':'kmeans'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63qxth1gYc8v"
   },
   "source": [
    "## Run GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyU0I3--rTgM"
   },
   "outputs": [],
   "source": [
    "latent = ex.get_latent()\n",
    "ps = PixelSegmenter(latent, \n",
    "                    tem.normalised_elemental_data, \n",
    "                    tem,\n",
    "                    method_args={'n_components':12, 'random_state':6, 'init_params':'kmeans'} )\n",
    "                    # can change random_state to different integer i.e. 10 or 0 to adjust the clustering result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyVkwD-kwFIF"
   },
   "source": [
    "## Checking latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjrxxOLFrVfu"
   },
   "outputs": [],
   "source": [
    "# Plot latent sapce (2-dimensional) with corresponding Gaussian models\n",
    "gui.view_latent_space(ps, color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKJ_bEDorXpp"
   },
   "outputs": [],
   "source": [
    "# visualise the latent space\n",
    "gui.check_latent_space(ps,ratio_to_be_shown=0.5, show_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47TKUHLorZyV"
   },
   "outputs": [],
   "source": [
    "# check the density of latent space\n",
    "gui.plot_latent_density(ps, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uFv-qDOLFye"
   },
   "source": [
    "## Checking each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0fAz4OErbxj"
   },
   "outputs": [],
   "source": [
    "ps.set_feature_list(['Al_Ka', 'C_Ka', 'Ca_Ka', 'Fe_Ka', 'K_Ka', 'O_Ka', 'Si_Ka', 'Ti_Ka', 'Zn_La'])\n",
    "gui.show_cluster_distribution(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7hCyeiKLLii"
   },
   "source": [
    "## Checking cluster map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH9196CXre1j"
   },
   "outputs": [],
   "source": [
    "# Plot phase map using the corresponding GM model\n",
    "gui.view_phase_map(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yizWZ7rrgvx"
   },
   "outputs": [],
   "source": [
    "gui.view_clusters_sum_spectra(ps, normalisation=True, spectra_range=(0,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDqkqAHpLaN0"
   },
   "source": [
    "# Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "weights, components = ps.get_unmixed_edx_profile(clusters_to_be_calculated='All', \n",
    "                                                 n_components='All',\n",
    "                                                 normalised=False, \n",
    "                                                 method='NMF', \n",
    "                                                 method_args={'init':'nndsvd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "gui.show_unmixed_weights_and_compoments(ps, weights, components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSIhNd4oLTHr"
   },
   "source": [
    "# Statistics infro from clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cermaBpurkg7"
   },
   "outputs": [],
   "source": [
    "gui.show_cluster_stats(ps)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tutorial_local",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
